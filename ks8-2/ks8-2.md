# Kubernetes series part 8-2

The objective of this tutorial is to prevent losing the data from our todo_list application. We'll achieve that via using a database that lives externally to our cluster. 

Even though the database is outside of the Kubernetes cluster, we'll still take advantage of Kubernetes services to allow our Python web application to connect to the external service.

**Note that the code changes in this episode are based off of ks8-1.**

## Code changes

1. Remove the `ks.database.deployment.yaml` since we won't use a database in a cluster in this episode.

    ```bash
    ➜ pwd
        ~/dev/github/redgate/ks/ks8-1
    ➜ rm ./ks/templates/ks.database.deployment.yaml
    ```

1. Install and configure a PostgreSQL database on your host machine

    See the [download & installation documentation](https://www.postgresql.org/download/) for your operating system

    Ensure that any configuration matches the contents of the `Values.yaml` file in the helm chart.
    For example, ensure the database name, database user name and port are all the same as defined in `Values.yaml`.

    Once the database is installed, you'll need to **manually run the SQL script to create the todo list**.

1. Edit the `ks.database.service.yaml` to map to our local PostgreSQL installation

    Replace the contents of the file with the following:
    
    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
    name: {{ .Release.Name }}-dbservice
    spec:
    type: ExternalName
    externalName: {{ .Values.database.externalName }}
    ```

1. Add an 'externalName' entry to your `Values.yaml` file

    ```yaml
    externalName: 192.168.64.1
    ```

    *NOTE*: The IP address used above is for the `xhyve` driver in Minikube.
    Depending on which driver you use, you will need to use a different IP address to connect out to the host machine.

    See [here for more information](https://github.com/kubernetes/minikube/blob/5f6075b2918e096dec30aecdd4e117c3c13f8e49/pkg/minikube/cluster/cluster.go#L287)

    Alternatively, if you are running this example in a cloud service, then you could point the external name to the hostname of a cloud-hosted database (e.g Amazon RDS, or equivalent).


## Set up and start ks8-2

1. start minikube and build docker images

    ```bash
    ➜ cd ks8-2
    ➜ minikube start
    ➜ eval $(minikube docker-env)

    # Ensure you've built the react app first
    ➜ cd app
    ➜ yarn
    ➜ yarn build
    
    ➜ docker build -f ./server/Dockerfile -t ks8webserverimage .
    ➜ docker build -f ./web/Dockerfile -t ks8webimage .
    ```

1. mount volume

    ```bash
    ➜ cd ks8-2
    ➜ minikube mount .:/mounted-ks8-src
    ```

1. install helm chart

    ```bash
    ➜ helm install ./ks -n ks
    ```

1. check app is working properly

    ```bash
    ➜ kubectl get pods
    NAME                         READY     STATUS    RESTARTS   AGE
    ks-ks8web-5658c6fd94-vk5ms   2/2       Running   0          5m
    ```

1. check logs

    ```bash
    ➜ kubectl logs ks-ks8web-5658c6fd94-vk5ms ks7webfrontend
    ➜ kubectl logs ks-ks8web-5658c6fd94-vk5ms ks7webserver
    ```

1. test app in browser

    ```bash
    ➜ minikube service ks-ks8web-service
    ```

1. connect to the postgresql server outside of the cluster

    ```bash
    # connect via psql command line
    ➜ psql -h 192.168.64.3 -p 32580 -U redgate -w ks
    psql (10.1, server 9.5.10)
    Type "help" for help.

    ks=# \dt
            List of relations
    Schema |   Name    | Type  |  Owner
    --------+-----------+-------+---------
    public | todo_list | table | redgate
    (1 row)

    ks=#
    ```

1. after inserting some data in the webserver, connect to the database as above and query the `todo_list` table

    ```bash
    ks=# select * from todo_list;
    id |    task_id    | name  | done
    ----+---------------+-------+------
    1 | 1516804951842 | one   | f
    2 | 1516804953872 | four  | f
    3 | 1516804952568 | two   | t
    4 | 1516804953344 | three | t
    (4 rows)
    ```

    Even if we delete our Kubernetes application, our data will persist because it lives entirely separate to the cluster.

    This can be extended to a cloud scenario, as you could run a PostgreSQL Amazon RDS instance and connect your AWS Kubernetes cluster using the same external service configuration. This way, you get the benefits of RDS like high availability, automated backups and automatic minor version updates, among other things.

    However, one of the things you may have noticed is the need to manually run SQL Scripts to intialise the database. This obviously prone to error. We'll come back to managing database schema and migrations with Kubernetes in later episodes.